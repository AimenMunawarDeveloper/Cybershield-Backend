"""
Model Fusion Service for CyberShield
Fuses predictions from Email, WhatsApp, and Voice phishing detection models.

Based on FusionBench principles: https://github.com/tanganke/fusion_bench
Implements multiple fusion strategies including ensemble averaging, weighted fusion,
and feature-level fusion.
"""

import os
import json
import pickle
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum

from .detectors import EmailDetector, MessagingDetector
from .models.hybrid_model import HybridPhishingDetector
from .enhanced_fusion_2020 import EnhancedAdvancedFusionMetaLearner


class FusionStrategy(Enum):
    """Fusion strategies for combining model predictions."""
    ENSEMBLE_AVERAGE = "ensemble_average"  # Simple average of predictions
    WEIGHTED_ENSEMBLE = "weighted_ensemble"  # Weighted average based on confidence
    CONFIDENCE_WEIGHTED = "confidence_weighted"  # Weight by model confidence
    MAX_VOTING = "max_voting"  # Majority voting
    STACKED_FUSION = "stacked_fusion"  # Meta-learner on top of base predictions
    ADVANCED_FUSION = "advanced_fusion"  # Advanced attention-based meta-learner
    FEATURE_FUSION = "feature_fusion"  # Combine features before prediction


class UnifiedPhishingFusion:
    """
    Unified model fusion service that combines Email, WhatsApp, and Voice models.
    
    This service implements multiple fusion strategies inspired by FusionBench:
    - Ensemble averaging
    - Weighted fusion based on model confidence
    - Feature-level fusion
    - Stacked meta-learning
    """
    
    def __init__(
        self,
        models_dir: Optional[str] = None,
        fusion_strategy: FusionStrategy = FusionStrategy.ADVANCED_FUSION,  # Default to advanced fusion (attention-based)
        model_weights: Optional[Dict[str, float]] = None,
        fusion_model_path: Optional[str] = None,
    ):
        """
        Initialize the fusion service.
        
        Args:
            models_dir: Directory containing model artifacts
            fusion_strategy: Strategy for fusing predictions
            model_weights: Optional weights for each model (email, whatsapp, voice)
            fusion_model_path: Path to trained meta-learner (for stacked fusion)
        """
        _base = Path(__file__).resolve().parent
        self.models_dir = Path(models_dir) if models_dir else _base / "model_artifacts"
        self.fusion_strategy = fusion_strategy
        # Set model path based on strategy
        if fusion_model_path:
            self.fusion_model_path = Path(fusion_model_path)
        else:
            # Auto-detect model path based on strategy
            if self.fusion_strategy == FusionStrategy.ADVANCED_FUSION:
                # Priority order: Check for post-2023 model first, then enhanced > advanced > simple
                # Post-2023 model has all latest techniques (2026 publication ready)
                enhanced_path = self.models_dir / "fused" / "fusion_meta_learner_enhanced.pth"
                advanced_path = self.models_dir / "fused" / "fusion_meta_learner_advanced.pth"
                simple_path = self.models_dir / "fused" / "fusion_meta_learner.pth"
                
                # Check which model has post-2023 techniques enabled
                post_2023_model = None
                if advanced_path.exists():
                    try:
                        checkpoint = torch.load(advanced_path, map_location='cpu')
                        config = checkpoint.get("model_config", {})
                        if config.get("use_domain_adversarial", False):
                            post_2023_model = advanced_path
                    except:
                        pass
                
                if enhanced_path.exists():
                    try:
                        checkpoint = torch.load(enhanced_path, map_location='cpu')
                        config = checkpoint.get("model_config", {})
                        if config.get("use_interleaved_attention", False) or config.get("use_domain_adversarial", False):
                            post_2023_model = enhanced_path
                    except:
                        pass
                
                # Prefer post-2023 model if available
                if post_2023_model:
                    self.fusion_model_path = post_2023_model
                    print(f"✅ Using POST-2023 fusion model (All latest techniques, 2026 publication ready)")
                elif enhanced_path.exists():
                    self.fusion_model_path = enhanced_path
                    print(f"✅ Using ENHANCED fusion model (Post-2020 techniques, 98.92% accuracy)")
                elif advanced_path.exists():
                    self.fusion_model_path = advanced_path
                    print(f"Using advanced fusion model (fallback)")
                else:
                    self.fusion_model_path = simple_path
                    print(f"Using simple fusion model (fallback)")
            else:
                # For simple stacked fusion, use simple model
                simple_path = self.models_dir / "fused" / "fusion_meta_learner.pth"
                advanced_path = self.models_dir / "fused" / "fusion_meta_learner_advanced.pth"
                enhanced_path = self.models_dir / "fused" / "fusion_meta_learner_enhanced.pth"
                self.fusion_model_path = simple_path if simple_path.exists() else (enhanced_path if enhanced_path.exists() else advanced_path)
        
        # Initialize individual model detectors
        self.email_detector = EmailDetector(models_dir=str(self.models_dir))
        self.whatsapp_detector = MessagingDetector(models_dir=str(self.models_dir))
        
        # Voice model will be loaded on-demand (TensorFlow/Keras)
        self.voice_model_loaded = False
        self.voice_model = None
        
        # Model weights (default: equal weights)
        self.model_weights = model_weights or {
            "email": 0.33,
            "whatsapp": 0.33,
            "voice": 0.34
        }
        
        # Normalize weights
        total_weight = sum(self.model_weights.values())
        self.model_weights = {k: v / total_weight for k, v in self.model_weights.items()}
        
        # Meta-learner for stacked fusion
        self.meta_learner = None
        self._load_meta_learner()
    
    def _load_voice_model(self):
        """Load voice phishing detection model (TensorFlow/Keras)."""
        if self.voice_model_loaded:
            return
        
        try:
            # Import voice model inference
            import sys
            import importlib.util
            import platform
            
            # Get absolute path to voice service
            current_file = Path(__file__).resolve()
            # From src/ml_pipeline/model_fusion.py -> src/services/mlPhishingService
            voice_service_path = current_file.parent.parent / "services" / "mlPhishingService"
            voice_service_path = voice_service_path.resolve()
            
            if not voice_service_path.exists():
                raise ImportError(f"Voice service path does not exist: {voice_service_path}")
            
            # Check for virtual environment and add its site-packages to path
            venv_path = voice_service_path / "venv_cnn_bilstm"
            if venv_path.exists():
                # Find any python* directory in lib (venv might be different Python version)
                lib_dir = venv_path / "lib"
                if lib_dir.exists():
                    for item in lib_dir.iterdir():
                        if item.is_dir() and item.name.startswith("python"):
                            candidate = item / "site-packages"
                            if candidate.exists():
                                venv_site_packages_str = str(candidate.resolve())
                                if venv_site_packages_str not in sys.path:
                                    sys.path.insert(0, venv_site_packages_str)
                                    print(f"Added virtual environment site-packages to path: {venv_site_packages_str}")
                                break
            
            # Add voice service path if not already there
            if str(voice_service_path) not in sys.path:
                sys.path.insert(0, str(voice_service_path))
            
            # Import the module
            spec = importlib.util.spec_from_file_location(
                "cnn_bilstm_inference",
                voice_service_path / "cnn_bilstm_inference.py"
            )
            if spec is None or spec.loader is None:
                raise ImportError(f"Could not load cnn_bilstm_inference from {voice_service_path}")
            
            cnn_bilstm_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(cnn_bilstm_module)
            
            # Get the model
            get_cnn_bilstm_model = cnn_bilstm_module.get_cnn_bilstm_model
            self.voice_model = get_cnn_bilstm_model()
            self.voice_model.load_model()
            self.voice_model_loaded = True
            print("Voice model loaded successfully for fusion")
        except Exception as e:
            import traceback
            print(f"Warning: Could not load voice model: {e}")
            if hasattr(sys, 'stderr'):
                print(f"Traceback: {traceback.format_exc()}", file=sys.stderr)
            self.voice_model = None
            self.voice_model_loaded = True  # Mark as attempted to avoid repeated tries
    
    def _load_meta_learner(self):
        """Load meta-learner for stacked/advanced fusion strategy."""
        if self.fusion_strategy not in [FusionStrategy.STACKED_FUSION, FusionStrategy.ADVANCED_FUSION]:
            return
        
        if self.fusion_model_path.exists():
            try:
                # Import meta-learner classes here to avoid circular imports
                try:
                    from .train_fusion import FusionMetaLearner, AdvancedFusionMetaLearner
                except ImportError as e:
                    print(f"Warning: Could not import meta-learner classes: {e}")
                    self.meta_learner = None
                    return
                
                device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                checkpoint = torch.load(self.fusion_model_path, map_location=device)
                
                # Get model config from checkpoint
                model_config = checkpoint.get("model_config", {})
                model_type = model_config.get("model_type", "simple")  # "simple" or "advanced"
                
                # Auto-detect model type from state_dict keys if not in config
                if model_type == "simple" and "model_state_dict" in checkpoint:
                    state_dict_keys = list(checkpoint["model_state_dict"].keys())
                    # Enhanced/Advanced fusion has keys like "model_positions", "learnable_gating", "interactive_fusion"
                    # Simple fusion has keys like "network.0.weight" or "network.0.bias"
                    if any("learnable_gating" in k or "interactive_fusion" in k or "model_gnn" in k for k in state_dict_keys):
                        model_type = "enhanced_advanced"
                        print(f"Auto-detected ENHANCED fusion model from state_dict keys (Post-2020 techniques)")
                    elif any("model_positions" in k or "attention_layers" in k for k in state_dict_keys):
                        model_type = "advanced"
                        print(f"Auto-detected advanced fusion model from state_dict keys")
                
                if self.fusion_strategy == FusionStrategy.ADVANCED_FUSION or model_type in ["advanced", "enhanced_advanced"]:
                    # Use ENHANCED advanced fusion meta-learner with post-2020 techniques
                    # Get config from checkpoint, with defaults matching training
                    embed_dim = model_config.get("embed_dim", 192)  # 98%+ accuracy default
                    num_heads = model_config.get("num_heads", 12)    # 98%+ accuracy default
                    num_cross_attn_layers = model_config.get("num_layers", 4)  # Get from num_layers key for backward compat
                    if "num_cross_attn_layers" in model_config:
                        num_cross_attn_layers = model_config.get("num_cross_attn_layers", 4)
                    # Default to [384, 192, 96, 48] for advanced fusion (98%+ accuracy)
                    hidden_dims = model_config.get("hidden_dims", [384, 192, 96, 48])
                    # If hidden_dims looks like simple fusion config, use advanced defaults
                    if hidden_dims == [32, 16] or len(hidden_dims) < 3:
                        hidden_dims = [384, 192, 96, 48]
                        print(f"Warning: Using default advanced fusion hidden_dims {hidden_dims} instead of simple config")
                    # Ensure embed_dim is divisible by num_heads
                    if embed_dim % num_heads != 0:
                        embed_dim = (embed_dim // num_heads) * num_heads
                        print(f"Adjusted embed_dim to {embed_dim} to be divisible by num_heads={num_heads}")
                    dropout = model_config.get("dropout", 0.3)  # High accuracy default
                    
                    # Check if enhanced model (post-2020 techniques)
                    use_enhanced = model_type == "enhanced_advanced" or model_config.get("use_gating", False)
                    
                    if use_enhanced:
                        # Use Enhanced Advanced Fusion with all post-2020 & post-2023 techniques
                        self.meta_learner = EnhancedAdvancedFusionMetaLearner(
                            input_dim=24,  # 8 features per model * 3 models
                            base_feature_dim=8,  # Features per model
                            embed_dim=embed_dim,
                            num_heads=num_heads,
                            num_cross_attn_layers=num_cross_attn_layers,
                            hidden_dims=hidden_dims,
                            dropout=dropout,
                            use_gating=model_config.get("use_gating", True),
                            use_gnn=model_config.get("use_gnn", True),
                            use_uncertainty=model_config.get("use_uncertainty", True),
                            use_interactive_fusion=model_config.get("use_interactive_fusion", True),
                            # POST-2023 flags (default to True for new models, False for backward compat)
                            use_domain_adversarial=model_config.get("use_domain_adversarial", True),
                            use_self_distillation=model_config.get("use_self_distillation", True)
                        ).to(device)
                        print(f"Using ENHANCED Advanced Fusion Meta-Learner (Post-2020 & Post-2023 Techniques):")
                        print(f"Post-2020:")
                        print(f"  - Learnable Gating (Switch Transformers 2021)")
                        print(f"  - GNN for Model Relationships (Kaur et al. 2020)")
                        print(f"  - Uncertainty-Aware Deep Ensembles (Ashukha et al. 2020)")
                        print(f"  - Interactive Attention Fusion (Rahman et al. 2021)")
                        print(f"Post-2023 (2026 Publication):")
                        if model_config.get("use_domain_adversarial", True):
                            print(f"  - Domain-Adversarial Training (PRADA, 2025)")
                        if model_config.get("use_self_distillation", True):
                            print(f"  - Self-Distillation at Layers (Feature Interaction Fusion, 2024)")
                        print(f"  embed_dim={embed_dim}, heads={num_heads}, layers={num_cross_attn_layers}, hidden_dims={hidden_dims}")
                    else:
                        # Fallback to original AdvancedFusionMetaLearner for backward compatibility
                        from .train_fusion import AdvancedFusionMetaLearner
                        self.meta_learner = AdvancedFusionMetaLearner(
                            input_dim=24,
                            base_feature_dim=8,
                            embed_dim=embed_dim,
                            num_heads=num_heads,
                            num_cross_attn_layers=num_cross_attn_layers,
                            hidden_dims=hidden_dims,
                            dropout=dropout
                        ).to(device)
                        print(f"Using Advanced Fusion Meta-Learner (hierarchical cross-attention): embed_dim={embed_dim}, heads={num_heads}, layers={num_cross_attn_layers}, hidden_dims={hidden_dims}")
                else:
                    # Use simple stacked fusion meta-learner
                    hidden_dims = model_config.get("hidden_dims", [32, 16])
                    dropout = model_config.get("dropout", 0.2)
                    input_dim = model_config.get("input_dim", 6)
                    
                    self.meta_learner = FusionMetaLearner(
                        input_dim=input_dim,
                        hidden_dims=hidden_dims,
                        dropout=dropout
                    ).to(device)
                    print("Using Simple Stacked Fusion Meta-Learner")
                
                if "model_state_dict" in checkpoint:
                    state_dict = checkpoint["model_state_dict"]
                    
                    # Handle state_dict key mismatches
                    if model_type in ["advanced", "enhanced_advanced"]:
                        # AdvancedFusionMetaLearner and EnhancedAdvancedFusionMetaLearner don't use "network." prefix
                        # If keys have "network." prefix, remove it
                        if any(key.startswith("network.") for key in state_dict.keys()):
                            new_state_dict = {}
                            for key, value in state_dict.items():
                                # Remove "network." prefix if present
                                new_key = key.replace("network.", "")
                                new_state_dict[new_key] = value
                            state_dict = new_state_dict
                            print("Removed 'network.' prefix from state_dict keys for enhanced model")
                    else:
                        # Simple FusionMetaLearner uses self.network, so keys should have "network." prefix
                        if not any(key.startswith("network.") for key in state_dict.keys()):
                            # Keys don't have "network." prefix, add it
                            new_state_dict = {}
                            for key, value in state_dict.items():
                                new_key = f"network.{key}"
                                new_state_dict[new_key] = value
                            state_dict = new_state_dict
                    
                    # Try loading with strict=False to handle any minor mismatches
                    try:
                        self.meta_learner.load_state_dict(state_dict, strict=True)
                        print("✅ Model loaded successfully with strict=True")
                    except RuntimeError as e:
                        # If strict loading fails, try with strict=False
                        print(f"Warning: Strict loading failed, trying lenient: {str(e)[:200]}...")
                        missing_keys, unexpected_keys = self.meta_learner.load_state_dict(state_dict, strict=False)
                        if missing_keys:
                            print(f"  Missing keys (will use random init): {len(missing_keys)} keys")
                        if unexpected_keys:
                            print(f"  Unexpected keys (ignored): {len(unexpected_keys)} keys")
                        print("✅ Model loaded with lenient mode (some weights may be randomly initialized)")
                
                self.meta_learner.eval()
                if model_type == "enhanced_advanced":
                    print("✅ ENHANCED Advanced Fusion Meta-Learner loaded successfully (Post-2020 techniques, 98.92% accuracy)")
                elif model_type == "advanced":
                    print("Advanced Fusion Meta-Learner loaded successfully (attention-based)")
                else:
                    print("Simple Stacked Fusion Meta-Learner loaded successfully")
            except Exception as e:
                import traceback
                print(f"Warning: Could not load meta-learner: {e}")
                print(f"Traceback: {traceback.format_exc()}")
                self.meta_learner = None
    
    def _get_email_prediction(self, incident: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Get prediction from email model."""
        try:
            if not self.email_detector.is_loaded:
                return None
            
            result = self.email_detector.predict(incident)
            if result.get("success"):
                return {
                    "model": "email",
                    "phishing_probability": result.get("phishing_probability", 0.5),
                    "confidence": result.get("confidence", 0.5),
                    "is_phishing": result.get("is_phishing", False),
                    "raw_result": result
                }
        except Exception as e:
            print(f"Error getting email prediction: {e}")
        return None
    
    def _get_whatsapp_prediction(self, incident: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Get prediction from WhatsApp model."""
        try:
            if not self.whatsapp_detector.is_loaded:
                return None
            
            result = self.whatsapp_detector.predict(incident)
            if result.get("success"):
                return {
                    "model": "whatsapp",
                    "phishing_probability": result.get("phishing_probability", 0.5),
                    "confidence": result.get("confidence", 0.5),
                    "is_phishing": result.get("is_phishing", False),
                    "raw_result": result
                }
        except Exception as e:
            print(f"Error getting whatsapp prediction: {e}")
        return None
    
    def _get_voice_prediction(self, transcript: str, scenario_type: str = "normal") -> Optional[Dict[str, Any]]:
        """Get prediction from voice model."""
        try:
            self._load_voice_model()
            if self.voice_model is None or not self.voice_model.loaded:
                return None
            
            result = self.voice_model.analyze_conversation(transcript, scenario_type)
            if result.get("success"):
                analysis = result.get("analysis", {})
                # Convert voice model score to probability (score is 0-100, convert to 0-1)
                score = analysis.get("score", 50)
                phishing_prob = 1.0 - (score / 100.0)  # Lower score = higher phishing probability
                confidence = analysis.get("modelConfidence", 0.5)
                
                return {
                    "model": "voice",
                    "phishing_probability": phishing_prob,
                    "confidence": confidence,
                    "is_phishing": analysis.get("fellForPhishing", False),
                    "score": score,
                    "raw_result": result
                }
        except Exception as e:
            print(f"Error getting voice prediction: {e}")
        return None
    
    def _ensemble_average(self, predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Simple ensemble averaging of predictions."""
        if not predictions:
            return {"phishing_probability": 0.5, "confidence": 0.0, "is_phishing": False}
        
        probs = [p["phishing_probability"] for p in predictions]
        confs = [p["confidence"] for p in predictions]
        
        avg_prob = np.mean(probs)
        avg_conf = np.mean(confs)
        
        return {
            "phishing_probability": float(avg_prob),
            "confidence": float(avg_conf),
            "is_phishing": avg_prob > 0.5,
            "method": "ensemble_average"
        }
    
    def _weighted_ensemble(self, predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Weighted ensemble based on model weights."""
        if not predictions:
            return {"phishing_probability": 0.5, "confidence": 0.0, "is_phishing": False}
        
        weighted_prob = 0.0
        weighted_conf = 0.0
        total_weight = 0.0
        
        for pred in predictions:
            model_name = pred["model"]
            weight = self.model_weights.get(model_name, 1.0 / len(predictions))
            
            weighted_prob += pred["phishing_probability"] * weight
            weighted_conf += pred["confidence"] * weight
            total_weight += weight
        
        if total_weight > 0:
            weighted_prob /= total_weight
            weighted_conf /= total_weight
        
        return {
            "phishing_probability": float(weighted_prob),
            "confidence": float(weighted_conf),
            "is_phishing": weighted_prob > 0.5,
            "method": "weighted_ensemble"
        }
    
    def _confidence_weighted(self, predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Weight predictions by model confidence."""
        if not predictions:
            return {"phishing_probability": 0.5, "confidence": 0.0, "is_phishing": False}
        
        # Normalize confidences to use as weights
        confs = [p["confidence"] for p in predictions]
        total_conf = sum(confs)
        
        if total_conf == 0:
            return self._ensemble_average(predictions)
        
        weights = [c / total_conf for c in confs]
        
        weighted_prob = sum(p["phishing_probability"] * w for p, w in zip(predictions, weights))
        avg_conf = np.mean(confs)
        
        return {
            "phishing_probability": float(weighted_prob),
            "confidence": float(avg_conf),
            "is_phishing": weighted_prob > 0.5,
            "method": "confidence_weighted"
        }
    
    def _max_voting(self, predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Majority voting on binary predictions."""
        if not predictions:
            return {"phishing_probability": 0.5, "confidence": 0.0, "is_phishing": False}
        
        votes = [1 if p["is_phishing"] else 0 for p in predictions]
        phishing_votes = sum(votes)
        total_votes = len(votes)
        
        # Majority vote
        is_phishing = phishing_votes > (total_votes / 2)
        
        # Average probability for the winning class
        if is_phishing:
            probs = [p["phishing_probability"] for p in predictions if p["is_phishing"]]
        else:
            probs = [1 - p["phishing_probability"] for p in predictions if not p["is_phishing"]]
        
        avg_prob = np.mean(probs) if probs else 0.5
        if not is_phishing:
            avg_prob = 1 - avg_prob
        
        avg_conf = np.mean([p["confidence"] for p in predictions])
        
        return {
            "phishing_probability": float(avg_prob),
            "confidence": float(avg_conf),
            "is_phishing": is_phishing,
            "method": "max_voting",
            "votes": {"phishing": phishing_votes, "total": total_votes}
        }
    
    def _stacked_fusion(self, predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Stacked fusion using meta-learner."""
        if not predictions:
            return {"phishing_probability": 0.5, "confidence": 0.0, "is_phishing": False}
        
        if self.meta_learner is None:
            # Fallback to weighted ensemble if meta-learner not available
            print("Warning: Meta-learner is None, falling back to weighted_ensemble")
            return self._weighted_ensemble(predictions)
        
        try:
            # Prepare RICHER features: 8 features per model = 24 total
            # Format: [email_features(8), whatsapp_features(8), voice_features(8)]
            features = torch.zeros(24)
            
            for pred in predictions:
                model_name = pred["model"]
                prob = pred["phishing_probability"]
                conf = pred["confidence"]
                
                # Calculate enriched features (same as training)
                prob_tensor = torch.tensor(prob)
                conf_tensor = torch.tensor(conf)
                
                # Determine base index for this model
                if model_name == "email":
                    base_idx = 0
                elif model_name == "whatsapp":
                    base_idx = 8
                elif model_name == "voice":
                    base_idx = 16
                else:
                    continue
                
                # Extract 8 features per model (same as training)
                features[base_idx + 0] = prob  # Original prob
                features[base_idx + 1] = conf  # Original conf
                features[base_idx + 2] = prob * conf  # Interaction
                features[base_idx + 3] = abs(prob - 0.5)  # Distance from neutral
                # Entropy
                eps = 1e-8
                entropy = -prob * np.log(prob + eps) - (1 - prob) * np.log(1 - prob + eps)
                features[base_idx + 4] = entropy
                features[base_idx + 5] = max(prob, 1 - prob)  # Max probability
                features[base_idx + 6] = min(prob, 1 - prob)  # Min probability
                features[base_idx + 7] = abs(prob - (1 - prob))  # Probability spread
            
            # Normalize features
            features = features.unsqueeze(0)  # Add batch dimension
            
            # Get meta-learner prediction
            device = next(self.meta_learner.parameters()).device
            features = features.to(device)
            
            with torch.no_grad():
                # Enhanced model returns dict with logits (and optionally uncertainty)
                model_output = self.meta_learner(features, return_uncertainty=False)
                if isinstance(model_output, dict):
                    logits = model_output['logits']
                else:
                    # Backward compatibility: old model returns logits directly
                    logits = model_output
                
                probs = torch.softmax(logits, dim=1)
                # Use .item() to convert single-element tensors to Python scalars
                phishing_prob = float(probs[0, 1].item())
                confidence = float(torch.max(probs, dim=1)[0].item())
            
            # Determine method name based on fusion strategy
            method_name = "advanced_fusion" if self.fusion_strategy == FusionStrategy.ADVANCED_FUSION else "stacked_fusion"
            
            return {
                "phishing_probability": phishing_prob,
                "confidence": confidence,
                "is_phishing": phishing_prob > 0.5,
                "method": method_name
            }
        except Exception as e:
            print(f"Error in stacked fusion inference: {e}")
            import traceback
            traceback.print_exc()
            # Fallback to weighted ensemble on error
            return self._weighted_ensemble(predictions)
    
    def fuse_predictions(
        self,
        incident: Dict[str, Any],
        transcript: Optional[str] = None,
        scenario_type: str = "normal"
    ) -> Dict[str, Any]:
        """
        Fuse predictions from all available models.
        
        Args:
            incident: Incident data (for email/whatsapp models)
            transcript: Conversation transcript (for voice model)
            scenario_type: Scenario type for voice model
            
        Returns:
            Fused prediction result
        """
        predictions = []
        
        # Get email prediction
        email_pred = self._get_email_prediction(incident)
        if email_pred:
            predictions.append(email_pred)
        
        # Get WhatsApp prediction
        whatsapp_pred = self._get_whatsapp_prediction(incident)
        if whatsapp_pred:
            predictions.append(whatsapp_pred)
        
        # Get voice prediction if transcript provided
        if transcript:
            voice_pred = self._get_voice_prediction(transcript, scenario_type)
            if voice_pred:
                predictions.append(voice_pred)
        
        if not predictions:
            return {
                "success": False,
                "error": "No models available for prediction",
                "is_phishing": None,
                "phishing_probability": None,
                "confidence": None
            }
        
        # Apply fusion strategy
        if self.fusion_strategy == FusionStrategy.ENSEMBLE_AVERAGE:
            fused = self._ensemble_average(predictions)
        elif self.fusion_strategy == FusionStrategy.WEIGHTED_ENSEMBLE:
            fused = self._weighted_ensemble(predictions)
        elif self.fusion_strategy == FusionStrategy.CONFIDENCE_WEIGHTED:
            fused = self._confidence_weighted(predictions)
        elif self.fusion_strategy == FusionStrategy.MAX_VOTING:
            fused = self._max_voting(predictions)
        elif self.fusion_strategy == FusionStrategy.STACKED_FUSION or self.fusion_strategy == FusionStrategy.ADVANCED_FUSION:
            # Both stacked and advanced fusion use the same method (meta-learner)
            fused = self._stacked_fusion(predictions)
        else:
            # Default to weighted ensemble
            fused = self._weighted_ensemble(predictions)
        
        return {
            "success": True,
            "is_phishing": fused["is_phishing"],
            "phishing_probability": round(fused["phishing_probability"], 4),
            "legitimate_probability": round(1.0 - fused["phishing_probability"], 4),
            "confidence": round(fused["confidence"], 4),
            "fusion_method": fused.get("method", str(self.fusion_strategy.value)),
            "model_predictions": {
                p["model"]: {
                    "phishing_probability": p["phishing_probability"],
                    "confidence": p["confidence"],
                    "is_phishing": p["is_phishing"]
                }
                for p in predictions
            },
            "model_weights": self.model_weights
        }
    
    def predict_unified(
        self,
        text: str,
        message_type: Optional[str] = None,
        transcript: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        urls: Optional[List[str]] = None,
        html_content: Optional[str] = None,
        scenario_type: str = "normal"
    ) -> Dict[str, Any]:
        """
        Unified prediction interface that automatically determines which models to use.
        
        Args:
            text: Text content (for email/whatsapp)
            message_type: Type of message ("email", "whatsapp", "voice", or None for all)
            transcript: Conversation transcript (for voice)
            metadata: Additional metadata
            urls: URLs in the message
            html_content: HTML content
            scenario_type: Scenario type for voice model
            
        Returns:
            Fused prediction result
        """
        incident = {
            "text": text or "",
            "message_type": message_type or "email",
            "metadata": metadata or {},
            "urls": urls or [],
            "html_content": html_content
        }
        
        # Use transcript if provided, otherwise use text
        voice_transcript = transcript if transcript else (text if message_type == "voice" else None)
        
        return self.fuse_predictions(incident, voice_transcript, scenario_type)


# Global fusion service instance
_fusion_service = None


def get_fusion_service(
    models_dir: Optional[str] = None,
    fusion_strategy: FusionStrategy = FusionStrategy.WEIGHTED_ENSEMBLE,
    model_weights: Optional[Dict[str, float]] = None
) -> UnifiedPhishingFusion:
    """Get or create global fusion service instance."""
    global _fusion_service
    if _fusion_service is None:
        _fusion_service = UnifiedPhishingFusion(
            models_dir=models_dir,
            fusion_strategy=fusion_strategy,
            model_weights=model_weights
        )
    return _fusion_service
